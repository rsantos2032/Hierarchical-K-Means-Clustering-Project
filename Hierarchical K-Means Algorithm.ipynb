{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "from collections import deque\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_train = pd.read_csv('MNIST_train.csv')\n",
    "MNIST_test = pd.read_csv('MNIST_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use hierarchical k-means to build a dictionary of image patches.\n",
    "For untouched images, construct a collection of 10 × 10 image patches.\n",
    "You should extract these patches from the training images on an overlapping 4×4 grid, meaning that each training image produces 16 overlapping\n",
    "patches (so you could have 960,000 training patches!). For each training\n",
    "image, choose one of these patches uniformly and at random. Now subsample this dataset of 60,000 patches uniformly and at random to produce\n",
    "a 6000 element dataset. Cluster this dataset to 50 centers. Now build 50\n",
    "datasets, one per cluster center. Do this by taking each element of the\n",
    "60,000 patch dataset, finding which of the cluster centers is closest to it,\n",
    "and putting the patch in that center’s dataset. Now cluster each of these\n",
    "datasets to 50 centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_images_into_patches(image_id, image, dictionary):    \n",
    "    image = (image.values).reshape(28, 28)\n",
    "    image_dictionary = {}\n",
    "    for it in range(16):\n",
    "        #patch = []\n",
    "        patch = deque()\n",
    "        i_low = -1\n",
    "        i_high = -1\n",
    "        #count = 0\n",
    "        \n",
    "        if it >= 0 and it <= 3:\n",
    "            i_low = 0\n",
    "            i_high = 10\n",
    "        elif it >= 4 and it <= 7:\n",
    "            i_low = 4\n",
    "            i_high = 14\n",
    "        elif it >= 8 and it <= 11:\n",
    "            i_low = 14\n",
    "            i_high = 24\n",
    "        else:\n",
    "            i_low = 18\n",
    "            i_high = 28\n",
    "            \n",
    "        for i in range(i_low, i_high):\n",
    "            j_low = -1\n",
    "            j_high = -1\n",
    "            \n",
    "            if it % 4 == 0:\n",
    "                j_low = 18\n",
    "                j_high = 28\n",
    "            elif it % 3 == 0:\n",
    "                j_low = 14\n",
    "                j_high = 24\n",
    "            elif it % 2 == 0:\n",
    "                j_low = 4\n",
    "                j_high = 14\n",
    "            else:\n",
    "                j_low = 0\n",
    "                j_high = 10\n",
    "            \n",
    "            for j in range(j_low, j_high):\n",
    "                patch.append(image[i][j])\n",
    "                \n",
    "        image_dictionary[it] = patch\n",
    "    dictionary[image_id] = image_dictionary    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_dictionary = {}\n",
    "for image_id in range(60000):\n",
    "    image = MNIST_train.loc[:, MNIST_train.columns != 'labels'].iloc[image_id]\n",
    "    image = (image.values).reshape(28, 28)\n",
    "    image_dictionary = {}\n",
    "    for it in range(16):\n",
    "        patch = deque()\n",
    "        i_low = -1\n",
    "        i_high = -1\n",
    "        \n",
    "        if it >= 0 and it <= 3:\n",
    "            i_low = 0\n",
    "            i_high = 10\n",
    "        elif it >= 4 and it <= 7:\n",
    "            i_low = 4\n",
    "            i_high = 14\n",
    "        elif it >= 8 and it <= 11:\n",
    "            i_low = 14\n",
    "            i_high = 24\n",
    "        else:\n",
    "            i_low = 18\n",
    "            i_high = 28\n",
    "            \n",
    "        for i in range(i_low, i_high):\n",
    "            j_low = -1\n",
    "            j_high = -1\n",
    "            \n",
    "            if it % 4 == 0:\n",
    "                j_low = 18\n",
    "                j_high = 28\n",
    "            elif it % 3 == 0:\n",
    "                j_low = 14\n",
    "                j_high = 24\n",
    "            elif it % 2 == 0:\n",
    "                j_low = 4\n",
    "                j_high = 14\n",
    "            else:\n",
    "                j_low = 0\n",
    "                j_high = 10\n",
    "            \n",
    "            for j in range(j_low, j_high):\n",
    "                patch.append(image[i][j])\n",
    "                \n",
    "        image_dictionary[it] = patch\n",
    "    patch_dictionary[image_id] = image_dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = []\n",
    "for i in range(100):\n",
    "    col_names.append(\"Pixel \" + str(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59999\n"
     ]
    }
   ],
   "source": [
    "random.seed(498)\n",
    "patch_training_df = pd.DataFrame(columns = col_names)\n",
    "for i in range(60000):\n",
    "    choose_patch = random.randint(0,15)\n",
    "    patch_training_df.loc[i] = patch_dictionary[i][choose_patch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(498)\n",
    "patch_training_df_sample = patch_training_df.sample(6000)\n",
    "indices = patch_training_df_sample.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_cluster = KMeans(n_clusters=50)\n",
    "patch_cluster_fit = patch_cluster.fit_predict(patch_training_df_sample)\n",
    "patch_cluster_centers = patch_cluster.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_data_collections = []\n",
    "for i in range(50):\n",
    "    cluster_data_collections.append(pd.DataFrame(columns=col_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_center = patch_cluster.predict(patch_training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(60000):\n",
    "    cluster_data_collections[closest_center[i]] = cluster_data_collections[closest_center[i]].append(patch_training_df.loc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_center_collections = []\n",
    "for i in range(50):\n",
    "    internal_cluster = KMeans(n_clusters=50)\n",
    "    internal_cluster_fit = internal_cluster.fit_predict(cluster_data_collections[i])\n",
    "    cluster_center_collections.append(internal_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now have a dictionary of 2500 entries. For each query image, construct a set of 10 × 10 patches on an overlapping 4 × 4 grid. Now for\n",
    "each of the centers, you should extract 9 patches. Assume the center is\n",
    "at (x, y); obtain 9 patches by extracting a patch centered at (x − 1, y −\n",
    "1),(x, y − 1),...,(x + 1, y + 1). This means each test image will have 144\n",
    "associated patches. Now use your dictionary to find the closest center to\n",
    "each patch, and construct a histogram of patches for each test image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_image_into_smaller_patches(image_id, image, dictionary):\n",
    "    image = (image.values).reshape(28, 28)\n",
    "    image_dictionary = {}\n",
    "    patch_list = []\n",
    "    \n",
    "    for it in range(16):\n",
    "        patch_1 = []\n",
    "        patch_2 = []\n",
    "        patch_3 = []\n",
    "        patch_4 = []\n",
    "        patch_5 = []\n",
    "        patch_6 = []\n",
    "        patch_7 = []\n",
    "        patch_8 = []\n",
    "        patch_9 = []\n",
    "        \n",
    "        i_low = -1\n",
    "        i_high = -1\n",
    "        counter = 0\n",
    "        \n",
    "        if it >= 0 and it <= 3:\n",
    "            i_low = 0\n",
    "            i_high = 10\n",
    "        elif it >= 4 and it <= 7:\n",
    "            i_low = 4\n",
    "            i_high = 14\n",
    "        elif it >= 8 and it <= 11:\n",
    "            i_low = 14\n",
    "            i_high = 24\n",
    "        else:\n",
    "            i_low = 18\n",
    "            i_high = 28\n",
    "            \n",
    "        for i in range(i_low, i_high):\n",
    "            j_low = -1\n",
    "            j_high = -1\n",
    "            \n",
    "            if it % 4 == 0:\n",
    "                j_low = 18\n",
    "                j_high = 28\n",
    "            elif it % 3 == 0:\n",
    "                j_low = 14\n",
    "                j_high = 24\n",
    "            elif it % 2 == 0:\n",
    "                j_low = 4\n",
    "                j_high = 14\n",
    "            else:\n",
    "                j_low = 0\n",
    "                j_high = 10\n",
    "            \n",
    "            for j in range(j_low, j_high):\n",
    "                if (i == 0 or j == 0):\n",
    "                    patch_1.append(0)\n",
    "                else:\n",
    "                    patch_1.append(image[i-1][j-1])\n",
    "                \n",
    "                if (j == 0):\n",
    "                    patch_2.append(0)\n",
    "                else:\n",
    "                    patch_2.append(image[i][j-1])\n",
    "                    \n",
    "                if (i == 27 or j == 1):\n",
    "                    patch_3.append(0)\n",
    "                else:\n",
    "                    patch_3.append(image[i+1][j-1])\n",
    "                    \n",
    "                if (i == 0):\n",
    "                    patch_4.append(0)\n",
    "                else:\n",
    "                    patch_4.append(image[i-1][j])\n",
    "                    \n",
    "                patch_5.append(image[i][j])\n",
    "                \n",
    "                if (i == 27):\n",
    "                    patch_6.append(0)\n",
    "                else:\n",
    "                    patch_6.append(image[i+1][j])\n",
    "                    \n",
    "                if (i == 0 or j == 27):\n",
    "                    patch_7.append(0)\n",
    "                else:\n",
    "                    patch_7.append(image[i-1][j+1])\n",
    "                    \n",
    "                if (j == 27):\n",
    "                    patch_8.append(0)\n",
    "                else:\n",
    "                    patch_8.append(image[i][j+1])\n",
    "                    \n",
    "                if (i == 27 or j == 27):\n",
    "                    patch_9.append(0)\n",
    "                else:\n",
    "                    patch_9.append(image[i+1][j+1])\n",
    "                    \n",
    "        patch_list.append(patch_1)\n",
    "        patch_list.append(patch_2)\n",
    "        patch_list.append(patch_3)\n",
    "        patch_list.append(patch_4)\n",
    "        patch_list.append(patch_5)\n",
    "        patch_list.append(patch_6)\n",
    "        patch_list.append(patch_7)\n",
    "        patch_list.append(patch_8)\n",
    "        patch_list.append(patch_9)\n",
    "        \n",
    "    dictionary[image_id] = patch_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5999\n"
     ]
    }
   ],
   "source": [
    "training_dict = {}\n",
    "testing_dict = {}\n",
    "MNIST_train_subset = MNIST_train[MNIST_train.index.isin(indices)]\n",
    "for i in range(6000):\n",
    "    clear_output(wait = True)\n",
    "    print(i)\n",
    "    split_image_into_smaller_patches(i, MNIST_train_subset.loc[:, MNIST_train_subset.columns != 'labels'].iloc[i], training_dict)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999\n"
     ]
    }
   ],
   "source": [
    "for i in range(10000):\n",
    "    clear_output(wait = True)\n",
    "    print(i)\n",
    "    split_image_into_smaller_patches(i, MNIST_test.loc[:, MNIST_test.columns != 'labels'].iloc[i], testing_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_names = []\n",
    "for i in range(2500):\n",
    "    hist_names.append(\"Cluster \" + str(i+1))\n",
    "\n",
    "a = np.zeros(shape=(6000,2500))\n",
    "b = np.zeros(shape=(10000,2500))\n",
    "training_histogram = pd.DataFrame(a, columns = hist_names)\n",
    "testing_histogram = pd.DataFrame(b, columns = hist_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5999\n"
     ]
    }
   ],
   "source": [
    "for i in range(6000):\n",
    "    clear_output(wait = True)\n",
    "    print(i)\n",
    "    entry = [0] * 2500\n",
    "    for j in range(144):\n",
    "        init = patch_cluster.predict([training_dict[i][j]])[0]\n",
    "        entry_level = cluster_center_collections[init].predict([training_dict[i][j]])[0]\n",
    "        idx = ((init + 1) * (entry_level + 1)) - 1\n",
    "        entry[idx] += 1\n",
    "    training_histogram.loc[i] = entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999\n"
     ]
    }
   ],
   "source": [
    "for i in range(10000):\n",
    "    clear_output(wait = True)\n",
    "    print(i)\n",
    "    entry = [0] * 2500\n",
    "    for j in range(144):\n",
    "        init = patch_cluster.predict([testing_dict[i][j]])[0]\n",
    "        entry_level = cluster_center_collections[init].predict([testing_dict[i][j]])[0]\n",
    "        idx = ((init + 1) * (entry_level + 1)) - 1\n",
    "        entry[idx] += 1\n",
    "    testing_histogram.loc[i] = entry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a classifier using this histogram of patches\n",
    "representation. Evaluate this classifier on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = MNIST_train_subset[\"labels\"].reset_index(drop = True)\n",
    "test_labels = MNIST_test[\"labels\"].reset_index(drop = True)\n",
    "training_histogram = pd.concat([training_histogram, train_labels], axis=1)\n",
    "testing_histogram = pd.concat([testing_histogram, test_labels], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
       "            oob_score=False, random_state=498, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 50, random_state = 498)\n",
    "rf.fit(training_histogram[training_histogram.columns[:-1]], training_histogram[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = rf.predict(testing_histogram[testing_histogram.columns[:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 908,    0,    2,    4,    9,    4,   17,    7,   20,    9],\n",
       "       [   0, 1113,    5,    4,    4,    2,    1,    2,    4,    0],\n",
       "       [  31,    4,  823,   55,    4,   34,   12,   18,   40,   11],\n",
       "       [  18,    3,   20,  902,    3,   17,    8,   24,   11,    4],\n",
       "       [   1,    6,    7,    0,  906,    0,   20,   10,    3,   29],\n",
       "       [  13,    4,   28,  103,    9,  668,   19,    4,   30,   14],\n",
       "       [  43,    5,    5,    3,   19,    8,  859,    2,   10,    4],\n",
       "       [   7,   14,   22,   42,   16,    2,    2,  866,    5,   52],\n",
       "       [  47,    5,   22,   29,   30,   24,   25,   23,  744,   25],\n",
       "       [  18,   14,   12,   15,   24,   12,    2,   45,    9,  858]])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(test_labels, preds)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8647"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(test_labels, preds)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this part we will be changing the patch sample size for training from 6000 to 8000 and the number of cluster centers from 50 to 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(498)\n",
    "patch_training_df_sample = patch_training_df.sample(8000)\n",
    "indices = patch_training_df_sample.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_cluster = KMeans(n_clusters=30)\n",
    "patch_cluster_fit = patch_cluster.fit_predict(patch_training_df_sample)\n",
    "patch_cluster_centers = patch_cluster.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_data_collections = []\n",
    "for i in range(30):\n",
    "    cluster_data_collections.append(pd.DataFrame(columns=col_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_center = patch_cluster.predict(patch_training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(60000):\n",
    "    cluster_data_collections[closest_center[i]] = cluster_data_collections[closest_center[i]].append(patch_training_df.loc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_center_collections = []\n",
    "for i in range(30):\n",
    "    internal_cluster = KMeans(n_clusters=30)\n",
    "    internal_cluster_fit = internal_cluster.fit_predict(cluster_data_collections[i])\n",
    "    cluster_center_collections.append(internal_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7999\n"
     ]
    }
   ],
   "source": [
    "training_dict = {}\n",
    "testing_dict = {}\n",
    "MNIST_train_subset = MNIST_train[MNIST_train.index.isin(indices)]\n",
    "for i in range(8000):\n",
    "    clear_output(wait = True)\n",
    "    print(i)\n",
    "    split_image_into_smaller_patches(i, MNIST_train_subset.loc[:, MNIST_train_subset.columns != 'labels'].iloc[i], training_dict)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999\n"
     ]
    }
   ],
   "source": [
    "for i in range(10000):\n",
    "    clear_output(wait = True)\n",
    "    print(i)\n",
    "    split_image_into_smaller_patches(i, MNIST_test.loc[:, MNIST_test.columns != 'labels'].iloc[i], testing_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_names = []\n",
    "for i in range(900):\n",
    "    hist_names.append(\"Cluster \" + str(i+1))\n",
    "\n",
    "a = np.zeros(shape=(8000,900))\n",
    "b = np.zeros(shape=(10000,900))\n",
    "training_histogram = pd.DataFrame(a, columns = hist_names)\n",
    "testing_histogram = pd.DataFrame(b, columns = hist_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7999\n"
     ]
    }
   ],
   "source": [
    "for i in range(8000):\n",
    "    clear_output(wait = True)\n",
    "    print(i)\n",
    "    entry = [0] * 900\n",
    "    for j in range(144):\n",
    "        init = patch_cluster.predict([training_dict[i][j]])[0]\n",
    "        entry_level = cluster_center_collections[init].predict([training_dict[i][j]])[0]\n",
    "        idx = ((init + 1) * (entry_level + 1)) - 1\n",
    "        entry[idx] += 1\n",
    "    training_histogram.loc[i] = entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999\n"
     ]
    }
   ],
   "source": [
    "for i in range(10000):\n",
    "    clear_output(wait = True)\n",
    "    print(i)\n",
    "    entry = [0] * 900\n",
    "    for j in range(144):\n",
    "        init = patch_cluster.predict([testing_dict[i][j]])[0]\n",
    "        entry_level = cluster_center_collections[init].predict([testing_dict[i][j]])[0]\n",
    "        idx = ((init + 1) * (entry_level + 1)) - 1\n",
    "        entry[idx] += 1\n",
    "    testing_histogram.loc[i] = entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = MNIST_train_subset[\"labels\"].reset_index(drop = True)\n",
    "test_labels = MNIST_test[\"labels\"].reset_index(drop = True)\n",
    "training_histogram = pd.concat([training_histogram, train_labels], axis=1)\n",
    "testing_histogram = pd.concat([testing_histogram, test_labels], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
       "            oob_score=False, random_state=498, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 50, random_state = 498)\n",
    "rf.fit(training_histogram[training_histogram.columns[:-1]], training_histogram[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = rf.predict(testing_histogram[testing_histogram.columns[:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 935,    0,    5,    1,    5,    3,   20,    2,    8,    1],\n",
       "       [   0, 1121,    8,    0,    3,    1,    0,    1,    1,    0],\n",
       "       [  18,    2,  902,   19,   10,   11,   11,   14,   38,    7],\n",
       "       [   6,    0,   24,  915,    0,   13,    9,   20,   18,    5],\n",
       "       [   1,    9,    9,    0,  909,    1,   12,    7,    0,   34],\n",
       "       [  14,    2,   29,   78,    8,  698,   15,   10,   24,   14],\n",
       "       [  21,    6,    7,    4,   14,   10,  877,    2,   14,    3],\n",
       "       [   2,   12,   26,   12,   18,    1,    2,  905,    7,   43],\n",
       "       [  36,    6,   27,   27,   19,   21,   19,   27,  775,   17],\n",
       "       [  13,   10,    5,   11,   26,    5,    2,   49,    6,  882]])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(test_labels, preds)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8919"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(test_labels, preds)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10809999999999997"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = 1 - accuracy\n",
    "error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see here we performed better with the modified variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that in comparison to our ~11% error rate most of the error rates on the website have a 1~3% error rate. Our classifer did beat the linear classifer (1-layer NN) run with no preprocessing which has a 12% test error rate. Looking at the other linear classifiers we can also see that we've performed around the same. We can safely say that with a bit more tuning our clustering-to-classifer setup is as good as a linear NN classifiers from the website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy from Part C was 0.8647"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy from Part D was 0.8919"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
